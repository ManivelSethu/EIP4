/* Assignment 03 */

The base accuracy:  Accuracy on test data is: 81.92 
The highest accuracy obtained : 82.19

/* Baseline log */
390/390 [==============================] - 17s 43ms/step - loss: 1.8568 - acc: 0.2902 - val_loss: 1.4712 - val_acc: 0.4582
Epoch 2/50
390/390 [==============================] - 8s 19ms/step - loss: 1.3810 - acc: 0.4978 - val_loss: 1.1239 - val_acc: 0.5878
Epoch 3/50
390/390 [==============================] - 8s 19ms/step - loss: 1.1266 - acc: 0.5978 - val_loss: 0.9762 - val_acc: 0.6609
Epoch 4/50
390/390 [==============================] - 8s 19ms/step - loss: 0.9744 - acc: 0.6605 - val_loss: 0.8607 - val_acc: 0.6953
Epoch 5/50
390/390 [==============================] - 8s 19ms/step - loss: 0.8754 - acc: 0.6976 - val_loss: 0.8029 - val_acc: 0.7191
Epoch 6/50
390/390 [==============================] - 8s 19ms/step - loss: 0.7949 - acc: 0.7288 - val_loss: 0.7262 - val_acc: 0.7539
Epoch 7/50
390/390 [==============================] - 8s 19ms/step - loss: 0.7488 - acc: 0.7426 - val_loss: 0.7537 - val_acc: 0.7468
Epoch 8/50
390/390 [==============================] - 7s 19ms/step - loss: 0.7077 - acc: 0.7594 - val_loss: 0.6840 - val_acc: 0.7687
Epoch 9/50
390/390 [==============================] - 8s 19ms/step - loss: 0.6597 - acc: 0.7759 - val_loss: 0.6675 - val_acc: 0.7718
Epoch 10/50
390/390 [==============================] - 8s 19ms/step - loss: 0.6370 - acc: 0.7832 - val_loss: 0.6516 - val_acc: 0.7797
Epoch 11/50
390/390 [==============================] - 8s 20ms/step - loss: 0.6055 - acc: 0.7945 - val_loss: 0.6109 - val_acc: 0.7948
Epoch 12/50
390/390 [==============================] - 8s 19ms/step - loss: 0.5857 - acc: 0.8011 - val_loss: 0.6498 - val_acc: 0.7831
Epoch 13/50
390/390 [==============================] - 8s 19ms/step - loss: 0.5637 - acc: 0.8097 - val_loss: 0.6207 - val_acc: 0.7918
Epoch 14/50
390/390 [==============================] - 8s 19ms/step - loss: 0.5569 - acc: 0.8107 - val_loss: 0.5926 - val_acc: 0.8037
Epoch 15/50
390/390 [==============================] - 8s 19ms/step - loss: 0.5297 - acc: 0.8184 - val_loss: 0.5747 - val_acc: 0.8141
Epoch 16/50
390/390 [==============================] - 8s 20ms/step - loss: 0.5180 - acc: 0.8240 - val_loss: 0.6010 - val_acc: 0.8094
Epoch 17/50
390/390 [==============================] - 8s 19ms/step - loss: 0.5027 - acc: 0.8292 - val_loss: 0.6061 - val_acc: 0.8026
Epoch 18/50
390/390 [==============================] - 8s 20ms/step - loss: 0.5004 - acc: 0.8296 - val_loss: 0.5928 - val_acc: 0.8080
Epoch 19/50
390/390 [==============================] - 8s 20ms/step - loss: 0.4868 - acc: 0.8338 - val_loss: 0.6050 - val_acc: 0.8080
Epoch 20/50
390/390 [==============================] - 8s 20ms/step - loss: 0.4759 - acc: 0.8384 - val_loss: 0.5743 - val_acc: 0.8164
Epoch 21/50
390/390 [==============================] - 8s 19ms/step - loss: 0.4633 - acc: 0.8412 - val_loss: 0.6184 - val_acc: 0.8056
Epoch 22/50
390/390 [==============================] - 8s 20ms/step - loss: 0.4529 - acc: 0.8456 - val_loss: 0.5832 - val_acc: 0.8189
Epoch 23/50
390/390 [==============================] - 8s 20ms/step - loss: 0.4434 - acc: 0.8504 - val_loss: 0.5626 - val_acc: 0.8211
Epoch 24/50
390/390 [==============================] - 8s 19ms/step - loss: 0.4379 - acc: 0.8508 - val_loss: 0.5838 - val_acc: 0.8160
Epoch 25/50
390/390 [==============================] - 8s 19ms/step - loss: 0.4269 - acc: 0.8544 - val_loss: 0.5835 - val_acc: 0.8158
Epoch 26/50
390/390 [==============================] - 8s 19ms/step - loss: 0.4227 - acc: 0.8573 - val_loss: 0.5781 - val_acc: 0.8213
Epoch 27/50
390/390 [==============================] - 8s 20ms/step - loss: 0.4153 - acc: 0.8596 - val_loss: 0.5904 - val_acc: 0.8123
Epoch 28/50
390/390 [==============================] - 8s 19ms/step - loss: 0.4167 - acc: 0.8591 - val_loss: 0.6134 - val_acc: 0.8058
Epoch 29/50
390/390 [==============================] - 8s 19ms/step - loss: 0.4048 - acc: 0.8642 - val_loss: 0.5934 - val_acc: 0.8078
Epoch 30/50
390/390 [==============================] - 8s 19ms/step - loss: 0.3959 - acc: 0.8655 - val_loss: 0.5816 - val_acc: 0.8202
Epoch 31/50
390/390 [==============================] - 8s 20ms/step - loss: 0.3911 - acc: 0.8662 - val_loss: 0.5693 - val_acc: 0.8158
Epoch 32/50
390/390 [==============================] - 8s 20ms/step - loss: 0.3857 - acc: 0.8690 - val_loss: 0.5636 - val_acc: 0.8238
Epoch 33/50
390/390 [==============================] - 8s 19ms/step - loss: 0.3897 - acc: 0.8686 - val_loss: 0.5809 - val_acc: 0.8182
Epoch 34/50
390/390 [==============================] - 8s 20ms/step - loss: 0.3872 - acc: 0.8690 - val_loss: 0.5706 - val_acc: 0.8231
Epoch 35/50
390/390 [==============================] - 8s 19ms/step - loss: 0.3752 - acc: 0.8736 - val_loss: 0.5821 - val_acc: 0.8216
Epoch 36/50
390/390 [==============================] - 8s 19ms/step - loss: 0.3732 - acc: 0.8745 - val_loss: 0.5731 - val_acc: 0.8274
Epoch 37/50
390/390 [==============================] - 8s 19ms/step - loss: 0.3687 - acc: 0.8759 - val_loss: 0.5709 - val_acc: 0.8240
Epoch 38/50
390/390 [==============================] - 8s 20ms/step - loss: 0.3719 - acc: 0.8738 - val_loss: 0.5757 - val_acc: 0.8214
Epoch 39/50
390/390 [==============================] - 8s 19ms/step - loss: 0.3625 - acc: 0.8782 - val_loss: 0.6006 - val_acc: 0.8201
Epoch 40/50
390/390 [==============================] - 8s 20ms/step - loss: 0.3597 - acc: 0.8792 - val_loss: 0.5670 - val_acc: 0.8253
Epoch 41/50
390/390 [==============================] - 8s 19ms/step - loss: 0.3497 - acc: 0.8819 - val_loss: 0.5986 - val_acc: 0.8197
Epoch 42/50
390/390 [==============================] - 8s 19ms/step - loss: 0.3597 - acc: 0.8802 - val_loss: 0.5860 - val_acc: 0.8211
Epoch 43/50
390/390 [==============================] - 8s 20ms/step - loss: 0.3398 - acc: 0.8848 - val_loss: 0.5830 - val_acc: 0.8281
Epoch 44/50
390/390 [==============================] - 8s 19ms/step - loss: 0.3405 - acc: 0.8860 - val_loss: 0.5985 - val_acc: 0.8174
Epoch 45/50
390/390 [==============================] - 8s 19ms/step - loss: 0.3462 - acc: 0.8846 - val_loss: 0.6088 - val_acc: 0.8224
Epoch 46/50
390/390 [==============================] - 8s 19ms/step - loss: 0.3371 - acc: 0.8862 - val_loss: 0.5856 - val_acc: 0.8291
Epoch 47/50
390/390 [==============================] - 8s 19ms/step - loss: 0.3336 - acc: 0.8859 - val_loss: 0.6035 - val_acc: 0.8265
Epoch 48/50
390/390 [==============================] - 8s 19ms/step - loss: 0.3337 - acc: 0.8893 - val_loss: 0.6029 - val_acc: 0.8214
Epoch 49/50
390/390 [==============================] - 8s 19ms/step - loss: 0.3323 - acc: 0.8898 - val_loss: 0.5916 - val_acc: 0.8205
Epoch 50/50
390/390 [==============================] - 8s 19ms/step - loss: 0.3229 - acc: 0.8913 - val_loss: 0.6115 - val_acc: 0.8192

---
/* My model log */

Epoch 1/50

Epoch 00001: LearningRateScheduler setting learning rate to 0.003.
50000/50000 [==============================] - 46s 926us/step - loss: 1.3930 - acc: 0.5142 - val_loss: 1.1987 - val_acc: 0.6030
Epoch 2/50

Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.
50000/50000 [==============================] - 39s 773us/step - loss: 0.9187 - acc: 0.6779 - val_loss: 0.8607 - val_acc: 0.7026
Epoch 3/50

Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.
50000/50000 [==============================] - 39s 776us/step - loss: 0.7573 - acc: 0.7347 - val_loss: 0.9339 - val_acc: 0.6795
Epoch 4/50

Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.
50000/50000 [==============================] - 39s 771us/step - loss: 0.6620 - acc: 0.7698 - val_loss: 0.7033 - val_acc: 0.7562
Epoch 5/50

Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.
50000/50000 [==============================] - 39s 777us/step - loss: 0.5930 - acc: 0.7919 - val_loss: 0.6869 - val_acc: 0.7640
Epoch 6/50

Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.
50000/50000 [==============================] - 39s 782us/step - loss: 0.5395 - acc: 0.8115 - val_loss: 0.6899 - val_acc: 0.7670
Epoch 7/50

Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.
50000/50000 [==============================] - 39s 776us/step - loss: 0.4886 - acc: 0.8274 - val_loss: 0.6382 - val_acc: 0.7834
Epoch 8/50

Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.
50000/50000 [==============================] - 39s 775us/step - loss: 0.4560 - acc: 0.8383 - val_loss: 0.6217 - val_acc: 0.7942
Epoch 9/50

Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.
50000/50000 [==============================] - 39s 783us/step - loss: 0.4171 - acc: 0.8533 - val_loss: 0.6244 - val_acc: 0.7907
Epoch 10/50

Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.
50000/50000 [==============================] - 39s 778us/step - loss: 0.3953 - acc: 0.8600 - val_loss: 0.5938 - val_acc: 0.8038
Epoch 11/50

Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.
50000/50000 [==============================] - 39s 779us/step - loss: 0.3636 - acc: 0.8701 - val_loss: 0.6607 - val_acc: 0.7831
Epoch 12/50

Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.
50000/50000 [==============================] - 39s 785us/step - loss: 0.3441 - acc: 0.8769 - val_loss: 0.6000 - val_acc: 0.8062
Epoch 13/50

Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.
50000/50000 [==============================] - 39s 780us/step - loss: 0.3266 - acc: 0.8824 - val_loss: 0.5917 - val_acc: 0.8080
Epoch 14/50

Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.
50000/50000 [==============================] - 39s 780us/step - loss: 0.3092 - acc: 0.8910 - val_loss: 0.5937 - val_acc: 0.8109
Epoch 15/50

Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.
50000/50000 [==============================] - 39s 787us/step - loss: 0.2984 - acc: 0.8936 - val_loss: 0.5958 - val_acc: 0.8099
Epoch 16/50

Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.
50000/50000 [==============================] - 39s 780us/step - loss: 0.2803 - acc: 0.9003 - val_loss: 0.5967 - val_acc: 0.8144
Epoch 17/50

Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.
50000/50000 [==============================] - 39s 780us/step - loss: 0.2740 - acc: 0.9031 - val_loss: 0.6108 - val_acc: 0.8124
Epoch 18/50

Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.
50000/50000 [==============================] - 39s 777us/step - loss: 0.2617 - acc: 0.9064 - val_loss: 0.6298 - val_acc: 0.8046
Epoch 19/50

Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.
50000/50000 [==============================] - 39s 780us/step - loss: 0.2512 - acc: 0.9091 - val_loss: 0.6014 - val_acc: 0.8128
Epoch 20/50

Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.
50000/50000 [==============================] - 39s 778us/step - loss: 0.2425 - acc: 0.9127 - val_loss: 0.6131 - val_acc: 0.8166
Epoch 21/50

Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.
50000/50000 [==============================] - 39s 777us/step - loss: 0.2312 - acc: 0.9172 - val_loss: 0.6063 - val_acc: 0.8124
Epoch 22/50

Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.
50000/50000 [==============================] - 39s 779us/step - loss: 0.2230 - acc: 0.9208 - val_loss: 0.6171 - val_acc: 0.8140
Epoch 23/50

Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.
50000/50000 [==============================] - 39s 774us/step - loss: 0.2222 - acc: 0.9201 - val_loss: 0.6204 - val_acc: 0.8140
Epoch 24/50

Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.
50000/50000 [==============================] - 39s 776us/step - loss: 0.2112 - acc: 0.9246 - val_loss: 0.6372 - val_acc: 0.8126
Epoch 25/50

Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.
50000/50000 [==============================] - 39s 774us/step - loss: 0.2085 - acc: 0.9255 - val_loss: 0.6210 - val_acc: 0.8096
Epoch 26/50

Epoch 00026: LearningRateScheduler setting learning rate to 0.0003342618.
50000/50000 [==============================] - 39s 771us/step - loss: 0.2023 - acc: 0.9268 - val_loss: 0.6381 - val_acc: 0.8102
Epoch 27/50

Epoch 00027: LearningRateScheduler setting learning rate to 0.0003227889.
50000/50000 [==============================] - 39s 773us/step - loss: 0.1929 - acc: 0.9313 - val_loss: 0.6259 - val_acc: 0.8134
Epoch 28/50

Epoch 00028: LearningRateScheduler setting learning rate to 0.0003120774.
50000/50000 [==============================] - 39s 780us/step - loss: 0.1890 - acc: 0.9311 - val_loss: 0.6289 - val_acc: 0.8186
Epoch 29/50

Epoch 00029: LearningRateScheduler setting learning rate to 0.000302054.
50000/50000 [==============================] - 39s 774us/step - loss: 0.1883 - acc: 0.9319 - val_loss: 0.6494 - val_acc: 0.8128
Epoch 30/50

Epoch 00030: LearningRateScheduler setting learning rate to 0.0002926544.
50000/50000 [==============================] - 39s 777us/step - loss: 0.1830 - acc: 0.9339 - val_loss: 0.6408 - val_acc: 0.8166
Epoch 31/50

Epoch 00031: LearningRateScheduler setting learning rate to 0.0002838221.
50000/50000 [==============================] - 39s 776us/step - loss: 0.1777 - acc: 0.9355 - val_loss: 0.6377 - val_acc: 0.8205
Epoch 32/50

Epoch 00032: LearningRateScheduler setting learning rate to 0.0002755074.
50000/50000 [==============================] - 39s 772us/step - loss: 0.1757 - acc: 0.9351 - val_loss: 0.6495 - val_acc: 0.8150
Epoch 33/50

Epoch 00033: LearningRateScheduler setting learning rate to 0.000267666.
50000/50000 [==============================] - 39s 775us/step - loss: 0.1726 - acc: 0.9377 - val_loss: 0.6486 - val_acc: 0.8150
Epoch 34/50

Epoch 00034: LearningRateScheduler setting learning rate to 0.0002602585.
50000/50000 [==============================] - 39s 774us/step - loss: 0.1682 - acc: 0.9397 - val_loss: 0.6532 - val_acc: 0.8150
Epoch 35/50

Epoch 00035: LearningRateScheduler setting learning rate to 0.00025325.
50000/50000 [==============================] - 39s 780us/step - loss: 0.1653 - acc: 0.9403 - val_loss: 0.6418 - val_acc: 0.8176
Epoch 36/50

Epoch 00036: LearningRateScheduler setting learning rate to 0.0002466091.
50000/50000 [==============================] - 39s 784us/step - loss: 0.1618 - acc: 0.9411 - val_loss: 0.6529 - val_acc: 0.8166
Epoch 37/50

Epoch 00037: LearningRateScheduler setting learning rate to 0.0002403076.
50000/50000 [==============================] - 39s 785us/step - loss: 0.1608 - acc: 0.9422 - val_loss: 0.6434 - val_acc: 0.8186
Epoch 38/50

Epoch 00038: LearningRateScheduler setting learning rate to 0.0002343201.
50000/50000 [==============================] - 39s 788us/step - loss: 0.1580 - acc: 0.9428 - val_loss: 0.6531 - val_acc: 0.8204
Epoch 39/50

Epoch 00039: LearningRateScheduler setting learning rate to 0.0002286237.
50000/50000 [==============================] - 39s 783us/step - loss: 0.1551 - acc: 0.9445 - val_loss: 0.6541 - val_acc: 0.8211
Epoch 40/50

Epoch 00040: LearningRateScheduler setting learning rate to 0.0002231977.
50000/50000 [==============================] - 39s 784us/step - loss: 0.1503 - acc: 0.9457 - val_loss: 0.6576 - val_acc: 0.8219
Epoch 41/50

Epoch 00041: LearningRateScheduler setting learning rate to 0.0002180233.
50000/50000 [==============================] - 39s 782us/step - loss: 0.1489 - acc: 0.9462 - val_loss: 0.6662 - val_acc: 0.8182
Epoch 42/50

Epoch 00042: LearningRateScheduler setting learning rate to 0.0002130833.
50000/50000 [==============================] - 39s 782us/step - loss: 0.1482 - acc: 0.9467 - val_loss: 0.6670 - val_acc: 0.8175
Epoch 43/50

Epoch 00043: LearningRateScheduler setting learning rate to 0.0002083623.
50000/50000 [==============================] - 39s 786us/step - loss: 0.1447 - acc: 0.9467 - val_loss: 0.6655 - val_acc: 0.8214
Epoch 44/50

Epoch 00044: LearningRateScheduler setting learning rate to 0.0002038459.
50000/50000 [==============================] - 39s 787us/step - loss: 0.1431 - acc: 0.9486 - val_loss: 0.6727 - val_acc: 0.8165
Epoch 45/50

Epoch 00045: LearningRateScheduler setting learning rate to 0.0001995211.
50000/50000 [==============================] - 39s 781us/step - loss: 0.1406 - acc: 0.9484 - val_loss: 0.6637 - val_acc: 0.8209
Epoch 46/50

Epoch 00046: LearningRateScheduler setting learning rate to 0.0001953761.
50000/50000 [==============================] - 39s 790us/step - loss: 0.1431 - acc: 0.9478 - val_loss: 0.6681 - val_acc: 0.8191
Epoch 47/50

Epoch 00047: LearningRateScheduler setting learning rate to 0.0001913998.
50000/50000 [==============================] - 39s 786us/step - loss: 0.1398 - acc: 0.9496 - val_loss: 0.6763 - val_acc: 0.8211
Epoch 48/50

Epoch 00048: LearningRateScheduler setting learning rate to 0.0001875821.
50000/50000 [==============================] - 39s 783us/step - loss: 0.1383 - acc: 0.9493 - val_loss: 0.6759 - val_acc: 0.8176
Epoch 49/50

Epoch 00049: LearningRateScheduler setting learning rate to 0.0001839137.
50000/50000 [==============================] - 39s 782us/step - loss: 0.1357 - acc: 0.9498 - val_loss: 0.6724 - val_acc: 0.8196
Epoch 50/50

Epoch 00050: LearningRateScheduler setting learning rate to 0.000180386.
50000/50000 [==============================] - 39s 781us/step - loss: 0.1317 - acc: 0.9527 - val_loss: 0.6831 - val_acc: 0.8184

/* Model * / 

model.add(SeparableConv2D(48, 3, 3, input_shape=(32, 32, 3), activation='relu',border_mode='same'))  #32 3x3 
model.add(BatchNormalization())
model.add(Dropout(0.05))

model.add(SeparableConv2D(48, 3, 3, activation='relu'))    #30  5x5 
model.add(BatchNormalization())
model.add(Dropout(0.05))

model.add(MaxPooling2D(pool_size=(2, 2)))   #15  6x6 
model.add(BatchNormalization())
model.add(Dropout(0.05))

model.add(SeparableConv2D(96, 3, 3, activation='relu',border_mode='same'))  #15 10x10
model.add(BatchNormalization())
model.add(Dropout(0.05))

model.add(SeparableConv2D(96, 3, 3, activation='relu'))   #13  14x14
model.add(BatchNormalization())
model.add(Dropout(0.05))

model.add(MaxPooling2D(pool_size=(2, 2)))   #6  16x16
model.add(BatchNormalization())
model.add(Dropout(0.05))

model.add(SeparableConv2D(192, 3, 3, activation='relu',border_mode='same')) #6 24x24
model.add(BatchNormalization())
model.add(Dropout(0.05))

model.add(SeparableConv2D(192, 3, 3, activation='relu'))    #4 32x32                      
model.add(BatchNormalization())
model.add(Dropout(0.05))

model.add(MaxPooling2D(pool_size=(2, 2)))  #2  36x36
model.add(BatchNormalization())
model.add(Dropout(0.05))

model.add(Flatten())
model.add(Dense(num_classes, activation='softmax'))
